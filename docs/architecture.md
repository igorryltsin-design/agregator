# Архитектура Agregator

Документ описывает техническую архитектуру Agregator: состав компонентов, принципы взаимодействия, поток обработки данных и эксплуатационные особенности.

## 1. Архитектурный профиль

Agregator реализован как локальная web-платформа со следующими слоями:

1. **Клиентский слой (UI)** - SPA-интерфейсы на React/TypeScript.
2. **Сервисный слой (API)** - Flask-приложение с бизнес-логикой и доступом к данным.
3. **Слой данных и обработки** - SQL-хранилище, файловая библиотека, фоновые задачи.

Ключевой принцип - **local-first**: данные и вычисления находятся в контуре пользователя/организации.

## 2. Компоненты системы

### 2.1 Frontend

- `frontend/` - основной интерфейс каталога, поиска, статистики и администрирования.
- `AiWord/` - встроенный редактор научных текстов, интегрированный с каталогом и AI-сервисами.
- Результаты сборки (`dist`) обслуживаются backend-приложением.

### 2.2 Backend

- `app.py` - точка входа Flask, маршрутизация, auth, запуск фоновых операций.
- `routes.py` - API-слой прикладных endpoint-ов.
- `agregator/services/` - изолированные сервисы:
  - поиск и фасеты;
  - HTTP-клиент к внешним AI-сервисам;
  - кэширование и управление сроком жизни данных;
  - логирование и диагностика.

### 2.3 Хранилища

- **SQL БД**
  - SQLite для локального/legacy режима;
  - PostgreSQL для production и масштабирования.
- **Файловая библиотека**
  - материалы пользователя в `SCAN_ROOT`.
- **Служебные данные**
  - runtime-настройки (`runtime_settings.json`);
  - кэш-файлы и логи.

### 2.4 Фоновые задачи

Отдельный контур фоновой обработки выполняет:

- сканирование библиотек;
- OCR и извлечение текста;
- транскрибацию аудио;
- переиндексацию;
- обслуживание кэшей.

Статус задач отображается через API и в UI.

## 3. Интеграции

### 3.1 AI/LLM

- LM Studio или любой OpenAI-compatible endpoint.
- Поддерживаются отдельные сценарии: keyword extraction, compose, rerank.
- Доступность AI-контуров контролируется конфигурацией и таймаутами.

### 3.2 OCR и обработка медиа

- OCR: Tesseract + Poppler.
- Аудио: ffmpeg + faster-whisper.
- Извлеченные данные включаются в индекс каталога.

## 4. Потоки данных

### 4.1 Импорт документа

1. Пользователь загружает файл или запускает сканирование каталога.
2. Backend валидирует входные параметры и создает задачу.
3. Фоновый worker извлекает метаданные и текст.
4. Материал сохраняется в БД и файловом индексе.
5. Обновляются фасеты, кеши и поисковые структуры.
6. UI получает статус и итог обработки.

### 4.2 Классический поиск

1. UI отправляет запрос с фильтрами.
2. Backend применяет ACL/ограничения коллекций.
3. Формируется выборка кандидатов по индексам и метаданным.
4. Возвращаются результаты, агрегаты и фильтры.

### 4.3 AI-поиск

1. Запрос нормализуется и расширяется ключевыми терминами.
2. Формируется пул кандидатов (метаданные + контентные сигналы).
3. Подбираются сниппеты и источники.
4. Генерируется ответ LLM с привязкой к найденным документам.
5. Возвращается ответ, список источников и служебная телеметрия.

## 5. Безопасность и доступ

- Сессионная аутентификация и роли пользователей.
- ACL на уровне коллекций.
- Разделение административных и пользовательских endpoint-ов.
- Рекомендовано: ограничения частоты запросов для дорогостоящих AI endpoint-ов.

## 6. Конфигурационная модель

- **Статическая конфигурация:** `.env`, compose env-файлы.
- **Runtime-конфигурация:** `runtime_settings.json` через UI/API.
- Изменения runtime-параметров применяются без полного пересоздания окружения.

## 7. Варианты развёртывания

- **Локальный single-host:** Python + SQLite/PostgreSQL.
- **Docker Compose:** контейнерный запуск с примонтированными каталогами данных.
- **Серверный rollout:** tarball + Ansible + systemd.

Подробности - в `docs/deployment.md`.
